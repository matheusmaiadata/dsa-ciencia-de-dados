{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c415e93d",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>Microsoft Fabric</font>\n",
    "## <font color='blue'>Silver Layer</font>\n",
    "\n",
    "Acompanhe as instruções no capítulo do curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95349bb-66d3-4b7e-80c3-3a66a929d4a6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade70ab-5d23-499e-b47c-6642ece4d2dd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import os dados do Lakehouse e carrega em um dataframe do Spark\n",
    "df = spark.read.option(\"multiline\", \"true\").json(f\"Files/dsa_dados_terremotos.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05734a1f-2148-438a-b025-853f2d872a23",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Reshape dos dados de terremotos extraindo e renomeando atributos-chave para análise posterior\n",
    "df = \\\n",
    "df.\\\n",
    "    select(\n",
    "        'id',\n",
    "        col('geometry.coordinates').getItem(0).alias('longitude'),\n",
    "        col('geometry.coordinates').getItem(1).alias('latitude'),\n",
    "        col('geometry.coordinates').getItem(2).alias('elevation'),\n",
    "        col('properties.title').alias('title'),\n",
    "        col('properties.place').alias('place_description'),\n",
    "        col('properties.sig').alias('sig'),\n",
    "        col('properties.mag').alias('mag'),\n",
    "        col('properties.magType').alias('magType'),\n",
    "        col('properties.time').alias('time'),\n",
    "        col('properties.updated').alias('updated')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb3eac-d2e6-431e-9652-630bf534d514",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Converte as colunas 'time' e 'updated' de milissegundos para o formato de registro de data e hora \n",
    "# para uma representação de data e hora de forma mais detalhada\n",
    "df = df.\\\n",
    "    withColumn('time', col('time')/1000).\\\n",
    "    withColumn('updated', col('updated')/1000).\\\n",
    "    withColumn('time', col('time').cast(TimestampType())).\\\n",
    "    withColumn('updated', col('updated').cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca637e-c9f0-4310-a0e8-a2f0fa7d25a2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Salva os dados na tabela silver\n",
    "df.write.mode('append').saveAsTable('dsa_terremotos_silver')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79719c32",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "84077e92-a108-418b-a307-a9358c2e158c",
    "default_lakehouse_name": "dsalake",
    "default_lakehouse_workspace_id": "56a5c21a-8d7e-4d57-a19f-a2fe5c2359d9"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
